{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from category_encoders import MEstimateEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from category_encoders import wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общая информация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cfg['house_pricing']['train_dataset'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(cfg['house_pricing']['test_dataset'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не все столбцы здесь выведены. Их список мы можем получить, используя аттрибут `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почистим данные в нескольких столбцах, основываясь на data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Exterior2nd\"] = train_df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them\n",
    "    # with the year the house was built\n",
    "train_df[\"GarageYrBlt\"] = train_df[\"GarageYrBlt\"].where(train_df.GarageYrBlt <= 2010, train_df.YearBuilt)\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "train_df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        \"3SsnPorch\": \"Threeseasonporch\",\n",
    "        }, inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = train_df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = train_df.select_dtypes(exclude=['object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_сols_with_missing = [col for col in num_df.columns \n",
    "                                 if num_df[col].isnull().any()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_сols_with_missing = [col for col in cat_df.columns \n",
    "                                 if cat_df[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[cat_сols_with_missing] = train_df[cat_сols_with_missing].fillna('NAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['GarageYrBlt','TotRmsAbvGrd','FirstFlrSF','GarageCars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer()\n",
    "\n",
    "train_df[num_сols_with_missing] = my_imputer.fit_transform(train_df[num_сols_with_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = train_df.select_dtypes(include=['object'])\n",
    "cat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.LandContour.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем наборе достаточно много категориальных признаков, и использовать их в таком виде, как они представлены в датасете, скорее всего нельзя. Это связано с тем, что модели в большинстве своем работают с евклидовыми или метрическими пространствами. Для перевода категориальных признаков в них используются различные техники, рассмотрим некоторые из них"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественным решением такой проблемы было бы однозначное отображение каждого значения в уникальное число. К примеру, мы могли бы преобразовать признак Street так: Pave в 0, а Grvl в 1. Эту простую операцию приходится делать часто, поэтому в модуле sklearn.preprocessing  именно для этой задачи реализован класс LabelEncoder. \n",
    "\n",
    "Метод fit этого класса находит все уникальные значения признака и строит таблицу для соответствия каждой категории некоторому числу, а метод transform непосредственно преобразует значения в числа. После fit у label_encoder будет доступно поле classes_, содержащее все уникальные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.LandContour.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "encoded_neigh = pd.Series(label_encoder.fit_transform(train_df['LandContour']))\n",
    "sns.histplot(encoded_neigh )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(22,8))\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "sns.histplot(train_df['LandContour'], ax=axes[0])\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "sns.histplot(encoded_neigh, ax=axes[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(enumerate(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: Что произойдет, если у нас появятся данные с другими категориями? LabelEncoder выдаст ошибку, что в словаре нет такой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.transform(train_df['LandContour'].replace('Low', 'low'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, при использовании этого метода нужно быть уверенным, что признак не может принимать неизвестных ранее значений.  Вопрос: как можно эту проблему решить?\n",
    "\n",
    "Основная проблема такого представления заключается даже не в этом, а в том, что числовой код создал евклидово представление для данных. Это значит, что теперь можно вычесть \"Low\" из \"Bnk\" и тд. Поэтому, например, методы, основанные на расстоянии, становятся больше неприменимы.\n",
    "\n",
    "LabelEncoding не принимает во внимание порядок переменных. Поэтому, если на самом деле известно, в каком порядке должны располагаться категории, лучше использовать другой метод энкодинга, например, порядковый. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Закодируйте все категориальные переменные джля обучающего и тестового датасетов с помощью Label Encoding. При этом: сначала обучите на обучающем и примените на тестовом, потом наоборот. Появятся ли ошибки из-за неизвестных категорий? \n",
    "Найдите параметр, контролирующий это поведение. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_categorical_columns(df):\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    return categorical_columns\n",
    "\n",
    "def label_encode(train_df, test_df, unknown_value=-1):\n",
    "    categorical_columns = find_categorical_columns(train_df)\n",
    "    \n",
    "    encoded_train_df = train_df.copy()\n",
    "    encoded_test_df = test_df.copy()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_df[col].astype(str))  \n",
    "        encoded_train_df[col] = le.transform(train_df[col].astype(str))\n",
    "        encoded_test_df[col] = test_df[col].astype(str).apply(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else unknown_value\n",
    "        )\n",
    "    \n",
    "    return encoded_train_df, encoded_test_df\n",
    "\n",
    "print(\"Обучаем на train_df, применяем к test_df:\")\n",
    "train_encoded, test_encoded = label_encode(train_df, test_df)\n",
    "print(\"Закодированный train_df:\")\n",
    "print(train_encoded)\n",
    "print(\"Закодированный test_df:\")\n",
    "print(test_encoded)\n",
    "\n",
    "print(\"\\nОбучаем на test_df, применяем к train_df:\")\n",
    "test_encoded, train_encoded = label_encode(test_df, train_df)\n",
    "print(\"Закодированный test_df:\")\n",
    "print(test_encoded)\n",
    "print(\"Закодированный train_df:\")\n",
    "print(train_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Используйте Ordinal Encoding для признака MS_Zoning. Задайте категории автоматически и подайте как параметр. Будут ли они закодированы одинаково или нет?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "train_df['MSZoning_encoded_auto'] = encoder.fit_transform(train_df[['MSZoning']])\n",
    "\n",
    "categories_manual = ['RL', 'RM', 'C (all)', 'FV', 'RH']\n",
    "encoder_manual = OrdinalEncoder(categories=[categories_manual])\n",
    "train_df['MSZoning_encoded_manual'] = encoder_manual.fit_transform(train_df[['MSZoning']])\n",
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot encoding является наиболее распространенным подходом для преобразования категориальных признаков, и он работает очень хорошо, если ваша категориальная переменная принимает небольшое количество значений (т.е. вы, как правило, не будете этого делать для переменных, которые принимают более 15 различных значений)\n",
    "\n",
    "Предположим, что некоторый признак может принимать 10 разных значений. В этом случае One Hot Encoding подразумевает создание 10 признаков, все из которых равны нулю за исключением одного. На позицию, соответствующую численному значению признака мы помещаем 1.\n",
    "Этот метод реализован в sklearn.preprocessing в классе OneHotEncoder. По умолчанию OneHotEncoder преобразует данные в разреженную матрицу, чтобы не расходовать память на хранение многочисленных нулей. Однако в нашем случае размер данных не является проблемой, поэтому мы будем использовать \"плотное\" представление.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "encoded_categorical_columns = pd.DataFrame(onehot_encoder.fit_transform(cat_df))\n",
    "encoded_categorical_columns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, у нас получилось  268 столбцов - именно столько уникальных значений могут принимать категориальные столбцы. Список категорий можно посмотреть с помощью `onehot_encoder.categories_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, можно сразу удалить категории, которые встречаются редко. Это можно сделать, задав значение параметра min_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False, min_frequency=0.3)\n",
    "encoded_categorical_columns = pd.DataFrame(onehot_encoder.fit_transform(cat_df))\n",
    "encoded_categorical_columns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме sklearn Pandas предлагает удобную функцию get_dummies для получения One Hot Encoding-а. Его минус в том, что нельзя с помощью transform менять новые наборы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(cat_df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя OneHotEncoder, мы можем четко контролировать, что происходит, когда он сталкивается с новой категорией. Если мы думаем, что это невозможно, то мы можем сказать ему, чтобы он выдал ошибку с handle_unknown=\"error\"; в противном случае мы можем указать ему просто установить значения во всех \"известных\" столбцах в 0, с помощью handle_unknown=\"ignore\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = cat_df.copy()\n",
    "temp_df['LandContour'] = temp_df['LandContour'].replace('Low', 'low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse_output=False, min_frequency=0.3, handle_unknown=\"ignore\")\n",
    "onehot_encoder.fit(cat_df)\n",
    "encoded_categorical_columns = pd.DataFrame(onehot_encoder.transform(temp_df))\n",
    "encoded_categorical_columns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, признаков получается очень и очень много (столько же, сколько и категорий). Однако есть способ использовать более плотное представление, а именно бинарное. Этот метод комбинирует LabelEncoding и BinaryEncoding. Обнако, широко он не используется. Пофантазируйте, почему это может быть?\n",
    "\n",
    "**Задание**: Определите, сколько столбцов получится после Binary Encoding."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Если k - количество признаков, то ceil(log2(k)) - количество столбцов после BinaryEncoding(ceil - округление вверх до ближайшего целого)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Encoding аналогичен label encoding-у, за исключением того, что здесь значения коррелируют непосредственно с целевой переменной. Среднее значение кода для каждой категории в лейбле элемента определяется средним значением целевой переменной на обучающих данных. Этот метод кодирования выявляет связь между аналогичными категориями, но отношения ограничены внутри категорий и цели.\n",
    "\n",
    "Преимущество этого метода кодирования заключается в том, что оно не влияет на объем данных и помогает в более быстром обучении. Часто обеспечивает более высокую точность (иногда резко высокую точность) из-за прямой корреляции между закодированной переменной и целевой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ сделать такое кодирование - присвоить категории среднее значение таргета для нее. Это обучаемый метод, т.к. мы используем выходы нашего моделирования для построения кодирования. Кстати, на самом деле необяхательно использовать настоящий таргет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Покажите, что происходит, когда этот метод применяется к постоянному предиктору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"LandContour_encoded\"] = train_df.groupby('LandContour')[\"SalePrice\"].transform(\"mean\")\n",
    "\n",
    "train_df[[\"LandContour\", \"SalePrice\", \"LandContour_encoded\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако такая кодировка создает несколько проблем. Во-первых, неизвестные категории. Может быть так, что какие-то категории просто изначально не попали в данные, а может, что их и не может быть (знакомо?). Чем можно закодировать такие категории?\n",
    "\n",
    "Во-вторых, это редкие категории. В тех случаях, когда какая-либо категория встречается в наборе данных лишь несколько раз, любые статистические данные, рассчитанные по ней, вряд ли будут очень точными. В нашем наборе данных LandContour значение Low появляется меньше 50 раз. \"Средняя\" цена, которую мы рассчитали, может быть не очень репрезентативной для зданий с таким значением, которые мы можем увидеть в будущем. Target Encoding редких категорий может сделать переобучение более вероятным. \n",
    "\n",
    "Решением этих проблем является добавление сглаживания. Идея состоит в том, чтобы смешать среднее значение по категории с общим средним значением. Редкие категории получают меньший вес в новом значении, в то время как недостающие категории просто получают среднее по всем остальным данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос: А как применить это  кодирование к классификации? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, в category encoders используется формула для рассчета веса \n",
    "`weight = 1/(1+exp(-(n–k)/f))`, где k - параметр minimal_samples_per_leaf, f - параметр smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder()\n",
    "encoded = target_encoder.fit_transform(train_df['LandContour'], train_df[\"SalePrice\"])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = ce.TargetEncoder(smoothing=100)\n",
    "encoded = target_encoder.fit_transform(train_df['LandContour'], train_df[\"SalePrice\"])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию, когда встречается неизвестное значение, то оно кодируется средним по всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df.copy()\n",
    "temp_df['LandContour'] = temp_df['LandContour'].replace('Low', 'low')\n",
    "encoded = target_encoder.transform(temp_df['LandContour'])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень большой минус target encoding - это \"протекание\" таргета, так как мы используем его значения для каждого элемента через аггрегацию. С этим можно бороться несколькими путями, например, усилить регуляризацию, добавлять шум, использовать K-Fold Target Encoding.\n",
    "\n",
    "Идея схожа с перекрестной валидацией. Мы делим данные на K-стратифицированные или случайные группы, заменяем наблюдения, присутствующие в M-й группе, на среднее целевое значение данных из всех остальных групп, кроме M-й. Мы в основном пытаемся использовать все данные, предоставленные нам, и не допускать утечки информации из целевой переменной, используя целевые зачения только из других групп для каждой категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = wrapper.NestedCVWrapper(ce.TargetEncoder(smoothing=100), 4)\n",
    "encoded = target_encoder.fit_transform(train_df['LandContour'], train_df[\"SalePrice\"])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df.copy()\n",
    "temp_df['LandContour'] = temp_df['LandContour'].replace('Low', 'low')\n",
    "encoded = target_encoder.transform(temp_df['LandContour'])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency encoding основан на замене категорий на их количество или частоту, вычисляемые на обучающем множестве. Этот метод чувствителен к выбросам, поэтому результат может быть нормализован или преобразован, например, с помощью логарифмического преобразования. Категории, которые неизвестны, могут быть заменены на 1 (в случае замены на число). Вопрос: этот метод обучаемый?\n",
    "\n",
    "Зачем использовать этот метод? Он полезен, когда таргет зависит от редкости признака (например, если представить стоимость вина). \n",
    "\n",
    "Хотя это не очень вероятно, число может быть одинаковым для некоторых переменных, что может привести к коллизии - кодированию двух категорий в качестве одного и того же значения. Приведет ли это к ухудшению качества модели или к улучшению, сказать нельзя, хотя в принципе такое поведение нежелательно. \n",
    "**Вопрос**: Что делать с новыми уровнями категорий? А что, если категории имеют очень большой перекос?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_encoder = ce.CountEncoder()\n",
    "encoded = count_encoder.fit_transform(train_df['LandContour'], train_df[\"SalePrice\"])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_encoder = ce.CountEncoder(normalize=True)\n",
    "encoded = count_encoder.fit_transform(train_df['LandContour'], train_df[\"SalePrice\"])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию новое значение учитывается как подсчитываемая категория, и ей дается значение 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = count_encoder.transform(temp_df['LandContour'])\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = count_encoder.transform(temp_df['LandContour'].replace('HLS', 'low'))\n",
    "encoded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте пайплайн/трансформер, который комбинирует несколько разных энкодингов воедино (для разных наборов признаков)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "one_hot_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('binary', BinaryEncoder())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', one_hot_transformer, ['MSZoning']),\n",
    "        ('ordinal', ordinal_transformer, ['LotShape']),\n",
    "        ('binary', binary_transformer, ['Neighborhood'])\n",
    "    ]\n",
    ")\n",
    "transformed_data = preprocessor.fit_transform(train_df)\n",
    "transformed_df = pd.DataFrame(transformed_data)\n",
    "\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение категорий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда удобно объединить категории, например, если это связано с природой данных или пониманием предмета. Например, можно обхединить немколько редких категорий. Однако, иногда это не помогает, ведь мы объединяем их только по признаку редкости. Но мы можем обучить какую-нибудь маленькую модель, или объединять категории по названиям. \n",
    "\n",
    "**Задание**: Выберите какой-нибудь признак и объедините те категории, которые встречаются редко. Выведите график с зависимостями таргета от этих категорий до и после объединения. Оцените, как изменилось распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = train_df['Neighborhood'].value_counts()\n",
    "\n",
    "print(\"Частота категорий:\")\n",
    "print(category_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title(\"Распределение категорий до объединения\")\n",
    "plt.xlabel(\"Категории\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.xticks(rotation=90) \n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "threshold = 30\n",
    "\n",
    "rare_categories = category_counts[category_counts < threshold].index\n",
    "\n",
    "train_df['Neighborhood_merged'] = train_df['Neighborhood'].apply(\n",
    "    lambda x: 'Other' if x in rare_categories else x\n",
    ")\n",
    "\n",
    "print(\"Данные после объединения:\")\n",
    "print(train_df['Neighborhood_merged'].value_counts())\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df)\n",
    "plt.title(\"Зависимость таргета от категорий до объединения\")\n",
    "plt.xlabel(\"Категории\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Neighborhood_merged', y='SalePrice', data=train_df)\n",
    "plt.title(\"Зависимость таргета от категорий после объединения\")\n",
    "plt.xlabel(\"Категории\")\n",
    "plt.ylabel(\"SalePrice\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3714695f2307aafe7da52bf6e53e38bc5469a267534973be7d21c816457eaf"
  },
  "kernelspec": {
   "display_name": "ml_2025",
   "language": "python",
   "name": "ml_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
